{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: numba in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from openai-whisper) (2.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from openai-whisper) (4.66.6)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from torch->openai-whisper) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\thanakornnemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "12.1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)              # ตรวจสอบเวอร์ชัน PyTorch\n",
    "print(torch.cuda.is_available())      # ตรวจสอบการรองรับ GPU\n",
    "print(torch.version.cuda)             # ตรวจสอบเวอร์ชัน CUDA ที่ใช้งานได้\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ThanakornNemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I love Thai culture. I would like to try cooking Thai food myself. Could you let comment a good restaurant for me? What do you like to do in your free time? Which Thai dish is your absolute favorite?\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\", device=\"cuda\")\n",
    "\n",
    "# Transcribe the .wav file\n",
    "result = model.transcribe(\"./demo/paeall.wav\")\n",
    "\n",
    "# Print the transcription result\n",
    "print(result[\"text\"])\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\windows\\system32\\src\\audiocraft\\audiocraft\\utils\\checkpoint.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(checkpoint_path, 'cpu')\n",
      "c:\\Users\\ThanakornNemo\\anaconda3\\envs\\voicecraft\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"USER\"] = \"me\" # TODO change this to your username\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import random\n",
    "from argparse import Namespace\n",
    "\n",
    "from data.tokenizer import (\n",
    "    AudioTokenizer,\n",
    "    TextTokenizer,\n",
    ")\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import shutil\n",
    "\n",
    "device = \"cpu\"\n",
    "voicecraft_name=\"830M_TTSEnhanced.pth\"\n",
    "\n",
    "from models import voicecraft\n",
    "model = voicecraft.VoiceCraft.from_pretrained(f\"pyp1/VoiceCraft_{voicecraft_name.replace('.pth', '')}\")\n",
    "phn2num = model.args.phn2num\n",
    "config = vars(model.args)\n",
    "model.to(device)\n",
    "\n",
    "print(f'device is {device}')\n",
    "\n",
    "encodec_fn = \"./pretrained_models/encodec_4cb2048_giga.th\"\n",
    "if not os.path.exists(encodec_fn):\n",
    "    print(\"Downloading encodec model...\")\n",
    "    os.system(f\"wget https://huggingface.co/pyp1/VoiceCraft/resolve/main/encodec_4cb2048_giga.th\")\n",
    "    shutil.move(\"encodec_4cb2048_giga.th\", \"./pretrained_models/encodec_4cb2048_giga.th\") # for windows\n",
    "    \n",
    "audio_tokenizer = AudioTokenizer(signature=encodec_fn, device=device) # will also put the neural codec model on gpu\n",
    "\n",
    "text_tokenizer = TextTokenizer(backend=\"espeak\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper text:  I love Thai culture. I would like to try cooking Thai food myself. Could you let comment a good restaurant for me? What do you like to do in your free time? Which Thai dish is your absolute favorite?\n",
      "whisper device is cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "orig_audio = \"./demo/paeall.wav\"\n",
    "\n",
    "import whisper\n",
    "whisper_model = whisper.load_model(\"base\", device=\"cuda\")\n",
    "result = whisper_model.transcribe(orig_audio)\n",
    "print(f'whisper text: {result[\"text\"]}')\n",
    "print(f'whisper device is {whisper_model.device}')\n",
    "\n",
    "orig_transcript = result[\"text\"]\n",
    "input_text = \" There was a man named Paetong who loved solstice very much. He thought about solstice every day and dreamed about solstice every night.\"\n",
    "\n",
    "# move the audio and transcript to temp folder\n",
    "temp_folder = \"./demo/temp\"\n",
    "os.makedirs(temp_folder, exist_ok=True)\n",
    "shutil.copy(orig_audio, temp_folder)\n",
    "filename = os.path.splitext(orig_audio.split(\"/\")[-1])[0]\n",
    "with open(f\"{temp_folder}/{filename}.txt\", \"w\") as f:\n",
    "    f.write(orig_transcript)\n",
    "\n",
    "# run MFA to get the alignment\n",
    "align_temp = f\"{temp_folder}/mfa_alignments\"\n",
    "!source ~/.bashrc && \\\n",
    "    conda activate voicecraft && \\\n",
    "    mfa align -v --clean -j 1 --output_format csv {temp_folder} \\\n",
    "        english_us_arpa english_us_arpa {align_temp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:phonemizer:words count mismatch on 700.0% of the lines (7/1)\n"
     ]
    }
   ],
   "source": [
    "target_transcript = orig_transcript + input_text\n",
    "audio_fn = f\"{temp_folder}/{filename}.wav\"\n",
    "info = torchaudio.info(audio_fn)\n",
    "audio_dur = info.num_frames / info.sample_rate\n",
    "cut_off_sec = audio_dur - 0.001\n",
    "prompt_end_frame = int(cut_off_sec * info.sample_rate)\n",
    "codec_audio_sr = 16000\n",
    "codec_sr = 50\n",
    "top_k = 0\n",
    "top_p = 0.9 # can also try 0.8, but 0.9 seems to work better\n",
    "temperature = 1\n",
    "silence_tokens=[1388,1898,131]\n",
    "kvcache = 1 # NOTE if OOM, change this to 0, or try the 330M model\n",
    "\n",
    "# NOTE adjust the below three arguments if the generation is not as good\n",
    "stop_repetition = 3 # NOTE if the model generate long silence, reduce the stop_repetition to 3, 2 or even 1\n",
    "sample_batch_size = 3 # NOTE: if the if there are long silence or unnaturally strecthed words, increase sample_batch_size to 4 or higher. What this will do to the model is that the model will run sample_batch_size examples of the same audio, and pick the one that's the shortest. So if the speech rate of the generated is too fast change it to a smaller number.\n",
    "seed = 1 # change seed if you are still unhappy with the result\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed)\n",
    "\n",
    "decode_config = {'top_k': top_k, 'top_p': top_p, 'temperature': temperature, 'stop_repetition': stop_repetition, 'kvcache': kvcache, \"codec_audio_sr\": codec_audio_sr, \"codec_sr\": codec_sr, \"silence_tokens\": silence_tokens, \"sample_batch_size\": sample_batch_size}\n",
    "from inference_tts_scale import inference_one_sample\n",
    "concated_audio, gen_audio = inference_one_sample(model, Namespace(**config), phn2num, text_tokenizer, audio_tokenizer, audio_fn, target_transcript, device, decode_config, prompt_end_frame)\n",
    "        \n",
    "# save segments for comparison\n",
    "concated_audio, gen_audio = concated_audio[0].cpu(), gen_audio[0].cpu()\n",
    "\n",
    "# display the audio\n",
    "from IPython.display import Audio\n",
    "print(\"concatenate prompt and generated:\")\n",
    "display(Audio(concated_audio, rate=codec_audio_sr))\n",
    "print(\"generated:\")\n",
    "display(Audio(gen_audio, rate=codec_audio_sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicecraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
